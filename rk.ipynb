{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import ast\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageDraw, ImageOps\n",
    "from sklearn.model_selection  import train_test_split\n",
    "import torch\n",
    "from torch import nn\n",
    "from collections import OrderedDict\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "categories = ['apple','banana']\n",
    "label_dict = {0:'apple',1:'banana'}\n",
    "\n",
    "# load data for each category\n",
    "classes = {}\n",
    "for category in categories:\n",
    "    data = pd.read_csv(\"../data/\" +category + \".csv\")\n",
    "    classes[category] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image manipulation utilities: \n",
    "\n",
    "def convert_to_PIL(drawing, width = 256, height = 256):\n",
    "\n",
    "    \n",
    "    # init\n",
    "    pil_img = Image.new('RGB', (width, height), 'white')\n",
    "    pixels = pil_img.load()\n",
    "            \n",
    "    draw = ImageDraw.Draw(pil_img)\n",
    "    \n",
    "    # draw strokes as lines\n",
    "    for x,y in drawing:\n",
    "        for i in range(1, len(x)):\n",
    "            draw.line((x[i-1], y[i-1], x[i], y[i]), fill=0)\n",
    "        \n",
    "    return pil_img\n",
    "\n",
    "def convert_to_np_raw(drawing, width = 256, height = 256):\n",
    "\n",
    "    # init array\n",
    "    img = np.zeros((28, 28))\n",
    "    \n",
    "    # create a PIL image out of drawing\n",
    "    pil_img = convert_to_PIL(drawing)\n",
    "    \n",
    "    #resize to 28,28\n",
    "    pil_img.thumbnail((28,28), Image.ANTIALIAS)\n",
    "    \n",
    "    pil_img = pil_img.convert('RGB')\n",
    "    pixels = pil_img.load()\n",
    "    \n",
    "    # fill in numpy array with pixel values\n",
    "    for i in range(0, 28):\n",
    "        for j in range(0, 28):\n",
    "            img[i, j] = 1 - pixels[j, i][0] / 255\n",
    "    \n",
    "    return img\n",
    "\n",
    "\n",
    "\n",
    "def view_image(img, width = 256, height = 256):\n",
    "    fig, ax = plt.subplots(figsize=(6,9))\n",
    "    ax.imshow(img.reshape(width, height).squeeze())\n",
    "    ax.axis('off')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values_dict = {}\n",
    "for category in categories:\n",
    "    data = classes[category][:3000]\n",
    "    values = [convert_to_np_raw(ast.literal_eval(img)).reshape(1, 784) for img in data['drawing'].values]\n",
    "    values_dict[category] = values\n",
    "    \n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for key, value in label_dict.items():\n",
    "    data_i = values_dict[value]\n",
    "    Xi = np.concatenate(data_i, axis = 0)\n",
    "    yi = np.full((len(Xi), 1), key).ravel()\n",
    "    \n",
    "    X.append(Xi)\n",
    "    y.append(yi)\n",
    "    \n",
    "X = np.concatenate(X, axis = 0)\n",
    "y = np.concatenate(y, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_images_grid(X, y):\n",
    "\n",
    "    fig, axs = plt.subplots(5, 5, figsize=(50,50))\n",
    "    \n",
    "    for label_num in range(0,25):\n",
    "        r_label = random.randint(0, len(X) - 1)\n",
    "        image = X[r_label].reshape(28,28)  #reshape images\n",
    "        i = label_num // 5\n",
    "        j = label_num % 5\n",
    "        axs[i,j].imshow(image) #plot the data\n",
    "        axs[i,j].axis('off')\n",
    "        \n",
    "        axs[i,j].set_title( label_dict[y[r_label]] ,fontsize=50)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_images_grid(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def npToImage(img):\n",
    "    img_r = img.reshape(28,28)\n",
    "\n",
    "    pil_img = Image.new('RGB', (28, 28), 'white')\n",
    "    pixels = pil_img.load()\n",
    "\n",
    "    for i in range(0, 28):\n",
    "        for j in range(0, 28):\n",
    "            if img_r[i, j] > 0:\n",
    "                pixels[j, i] = (255 - int(img_r[i, j] * 255), 255 - int(img_r[i, j] * 255), 255 - int(img_r[i, j] * 255))\n",
    "\n",
    "    return pil_img\n",
    "\n",
    "\n",
    "def toNp(pil_img, width = 256, height = 256):\n",
    "    pil_img = pil_img.convert('RGB')\n",
    "\n",
    "    img = np.zeros((width, height))\n",
    "    pixels = pil_img.load()\n",
    "\n",
    "    for i in range(0, width):\n",
    "        for j in range(0, height):\n",
    "            img[i, j] = 1 - pixels[j, i][0] / 255\n",
    "\n",
    "    return img\n",
    "\n",
    "def flip(src_im):\n",
    "    dst_im = src_im.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "    return dst_im\n",
    "\n",
    "\n",
    "def rotate(src_im, angle = 45, size = (28,28)):\n",
    "    dst_im = Image.new(\"RGBA\", size, \"white\")\n",
    "    src_im = src_im.convert('RGBA')\n",
    "\n",
    "    rot = src_im.rotate(angle)\n",
    "    dst_im.paste(rot, (0, 0), rot)\n",
    "\n",
    "    return dst_im\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,3, figsize=(50,50))\n",
    "\n",
    "np_img = X[100]\n",
    "np_img_flipped = toNp(flip(npToImage(np_img)), 28, 28)\n",
    "np_img_rotated = toNp(rotate(npToImage(np_img)), 28, 28)\n",
    "\n",
    "axs[0].set_title('original', fontsize = 50)\n",
    "axs[0].imshow(np_img.reshape(28, 28).squeeze())\n",
    "axs[0].axis('off')\n",
    "\n",
    "axs[1].set_title('flipped', fontsize = 50)\n",
    "axs[1].imshow(np_img_flipped.reshape(28, 28).squeeze())\n",
    "axs[1].axis('off')\n",
    "\n",
    "axs[2].set_title('rotated', fontsize = 50)\n",
    "axs[2].imshow(np_img_rotated.reshape(28, 28).squeeze())\n",
    "axs[2].axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_size, output_size, hidden_sizes, dropout = 0.0):\n",
    "\n",
    "    model = nn.Sequential(OrderedDict([\n",
    "                          ('fc1', nn.Linear(input_size, hidden_sizes[0])),\n",
    "                          ('relu1', nn.ReLU()),\n",
    "                          ('fc2', nn.Linear(hidden_sizes[0], hidden_sizes[1])),\n",
    "                          ('bn2', nn.BatchNorm1d(num_features=hidden_sizes[1])),\n",
    "                          ('relu2', nn.ReLU()),\n",
    "                          ('dropout', nn.Dropout(dropout)),\n",
    "                          ('fc3', nn.Linear(hidden_sizes[1], hidden_sizes[2])),\n",
    "                          ('bn3', nn.BatchNorm1d(num_features=hidden_sizes[2])),\n",
    "                          ('relu3', nn.ReLU()),\n",
    "                          ('logits', nn.Linear(hidden_sizes[2], output_size))]))\n",
    "\n",
    "    return model\n",
    "\n",
    "def fit_model(model, X_train, y_train, epochs = 100, n_chunks = 1000, learning_rate = 0.003, weight_decay = 0, optimizer = 'SGD'):\n",
    "\n",
    "    print(\"Fitting model with epochs = {epochs}, learning rate = {lr}\\n\"\\\n",
    "          .format(epochs = epochs, lr = learning_rate))\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    if (optimizer == 'SGD'):\n",
    "        optimizer = optim.SGD(model.parameters(), lr=learning_rate, weight_decay= weight_decay)\n",
    "    else:\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay= weight_decay)\n",
    "\n",
    "    print_every = 10\n",
    "\n",
    "    steps = 0\n",
    "\n",
    "    for e in range(epochs):\n",
    "        running_loss = 0\n",
    "\n",
    "        X_train, y_train = shuffle(X_train, y_train)\n",
    "\n",
    "        images = torch.chunk(X_train, n_chunks)\n",
    "        labels = torch.chunk(y_train, n_chunks)\n",
    "\n",
    "        for i in range(n_chunks):\n",
    "            steps += 1\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            output = model.forward(images[i])\n",
    "            loss = criterion(output, labels[i].squeeze())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        if epochs % print_every == 0:\n",
    "            print(\"Epoch: {}/{}... \".format(e+1, epochs),\n",
    "                  \"Loss: {:.4f}\".format(running_loss/print_every))\n",
    "\n",
    "            running_loss = 0\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preds(model, input):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        logits = model.forward(input)\n",
    "    ps = F.softmax(logits, dim=1)\n",
    "    return ps\n",
    "\n",
    "def get_labels(pred):\n",
    "    pred_np = pred.numpy()\n",
    "    pred_values = np.amax(pred_np, axis=1, keepdims=True)\n",
    "    pred_labels = np.array([np.where(pred_np[i, :] == pred_values[i, :])[0] for i in range(pred_np.shape[0])])\n",
    "    pred_labels = pred_labels.reshape(len(pred_np), 1)\n",
    "\n",
    "    return pred_labels\n",
    "\n",
    "def evaluate_model(model, train, y_train, test, y_test):\n",
    "    train_pred = get_preds(model, train)\n",
    "    train_pred_labels = get_labels(train_pred)\n",
    "\n",
    "    test_pred = get_preds(model, test)\n",
    "    test_pred_labels = get_labels(test_pred)\n",
    "\n",
    "    accuracy_train = accuracy_score(y_train, train_pred_labels)\n",
    "    accuracy_test = accuracy_score(y_test, test_pred_labels)\n",
    "\n",
    "    print(\"Accuracy score for train set is {} \\n\".format(accuracy_train))\n",
    "    print(\"Accuracy score for test set is {} \\n\".format(accuracy_test))\n",
    "\n",
    "    return accuracy_train, accuracy_test\n",
    "\n",
    "def shuffle(X_train, y_train):\n",
    "    X_train_shuffled = X_train.numpy()\n",
    "    y_train_shuffled = y_train.numpy().reshape((X_train.shape[0], 1))\n",
    "\n",
    "    permutation = list(np.random.permutation(X_train.shape[0]))\n",
    "    X_train_shuffled = X_train_shuffled[permutation, :]\n",
    "    y_train_shuffled = y_train_shuffled[permutation, :].reshape((X_train.shape[0], 1))\n",
    "\n",
    "    X_train_shuffled = torch.from_numpy(X_train_shuffled).float()\n",
    "    y_train_shuffled = torch.from_numpy(y_train_shuffled).long()\n",
    "\n",
    "    return X_train_shuffled, y_train_shuffled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = torch.from_numpy(X_train).float()\n",
    "labels = torch.from_numpy(y_train).long()\n",
    "test = torch.from_numpy(X_test).float()\n",
    "test_labels = torch.from_numpy(y_test).long()\n",
    "\n",
    "input_size = 784\n",
    "hidden_sizes = [128, 100, 64]\n",
    "output_size = 2\n",
    "\n",
    "dropout = 0.0\n",
    "weight_decay = 0.0\n",
    "n_chunks = 700\n",
    "learning_rate = 0.03\n",
    "optimizer = 'SGD'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc = []\n",
    "test_acc = []\n",
    "\n",
    "for epochs in np.arange(10, 60, 10):\n",
    "    model = build_model(input_size, output_size, hidden_sizes, dropout = dropout)\n",
    "\n",
    "    fit_model(model, train, labels, epochs = epochs, n_chunks = n_chunks, learning_rate = learning_rate, weight_decay = weight_decay, optimizer = 'SGD')\n",
    "    accuracy_train, accuracy_test = evaluate_model(model, train, y_train, test, y_test)\n",
    "\n",
    "    train_acc.append(accuracy_train)\n",
    "    test_acc.append(accuracy_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(10, 10 * (len(train_acc) + 1), 10)\n",
    "plt.plot(x, train_acc)\n",
    "plt.plot(x, test_acc)\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.title('Accuracy, learning_rate = ' + str(learning_rate), fontsize=14)\n",
    "plt.xlabel('Number of epochs', fontsize=11)\n",
    "plt.ylabel('Accuracy', fontsize=11)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Function creates test view of the model's prediction for image.\n",
    "\n",
    "def test_model(model, img):\n",
    "\n",
    "    # Convert 2D  to 1D image\n",
    "    img = img.resize_(1, 784)\n",
    "\n",
    "    ps = get_preds(model, img)\n",
    "    view_classify(img.resize_(1, 28, 28), ps)\n",
    "\n",
    "    \n",
    "#  Function to get predicted probabilities from the model for each class.\n",
    "def get_preds(model, input):\n",
    "\n",
    "\n",
    "    # Turn off gradients to speed up this part\n",
    "    with torch.no_grad():\n",
    "        logits = model.forward(input)\n",
    "    ps = F.softmax(logits, dim=1)\n",
    "    return ps\n",
    "\n",
    "\n",
    "# Function for viewing an image and it's predicted classes\n",
    "\n",
    "\n",
    "def view_classify(img, ps):\n",
    "\n",
    "    ps = ps.data.numpy().squeeze()\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(figsize=(6,9), ncols=2)\n",
    "    ax1.imshow(img.resize_(1, 28, 28).numpy().squeeze())\n",
    "    ax1.axis('off')\n",
    "    ax2.barh(np.arange(2), ps)\n",
    "    ax2.set_aspect(0.1)\n",
    "    ax2.set_yticks(np.arange(10))\n",
    "    ax2.set_yticklabels(['apple','bannana'], size='small');\n",
    "    ax2.set_title('Class Probability')\n",
    "    ax2.set_xlim(0, 1.1)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "# get prediction \n",
    "test_model(model, test[44])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
